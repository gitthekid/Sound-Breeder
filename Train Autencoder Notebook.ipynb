{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of train_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hMqWDc_m6rUC"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpJd3dlOCStH"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magenta/ddsp/blob/master/ddsp/colab/demos/train_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMqWDc_m6rUC"
      },
      "source": [
        "#Citation:\n",
        "https://github.com/magenta/ddsp\n",
        "The majority of the code used here is directly adapted from Google Magenta's Tone Transfer github\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpXo6phTiOQM"
      },
      "source": [
        "# Train a DDSP Autoencoder on GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn7CQ4GQizHy"
      },
      "source": [
        "## Install requirements to run model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "VxPuPR0j5Gs7"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install -qU ddsp[data_preparation]==1.0.1\n",
        "\n",
        "# Initialize global path for using google drive. \n",
        "DRIVE_DIR = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0fVn8yUJl_v"
      },
      "source": [
        "## Connect to google drive, to easily save checkpoints for autencoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6MXUbL6KeMn"
      },
      "source": [
        "#### Connects to google drive, and prompts a login"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m33xuTjEKazJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4vmxpj1LC7m"
      },
      "source": [
        "#### Connects to the folder (file pathway) where the training audio is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0bK6P9DMBTb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "ba133b71-baac-4c13-9230-325e8cebb2b3"
      },
      "source": [
        "DRIVE_DIR = '' #@param {type: \"string\"}\n",
        "import os\n",
        "assert os.path.exists(DRIVE_DIR)\n",
        "print('Drive Folder Exists:', DRIVE_DIR)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-959f49b39700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDRIVE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Drive Folder Exists:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDRIVE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DRIVE_DIR' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FELlizMtIxCH"
      },
      "source": [
        "## Make directories to save model and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd22WxEQI3FV"
      },
      "source": [
        "AUDIO_DIR = 'data/audio'\n",
        "AUDIO_FILEPATTERN = AUDIO_DIR + '/*'\n",
        "!mkdir -p \"$AUDIO_DIR\"\n",
        "\n",
        "if DRIVE_DIR:\n",
        "  SAVE_DIR = os.path.join(DRIVE_DIR, 'ddsp-solo-instrument')\n",
        "else:\n",
        "  SAVE_DIR = '/content/models/ddsp-solo-instrument'\n",
        "!mkdir -p \"$SAVE_DIR\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb4YD8woYD1H"
      },
      "source": [
        "## Prepare Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNhH7nEbX2db"
      },
      "source": [
        "#### Uploads the training audio files from the pre-defined file pathway"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itVKEzF6m3rY"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "from ddsp.colab import colab_utils\n",
        "\n",
        "if DRIVE_DIR:\n",
        "  mp3_files = glob.glob(os.path.join(DRIVE_DIR, '*.mp3'))\n",
        "  wav_files = glob.glob(os.path.join(DRIVE_DIR, '*.wav'))\n",
        "  audio_files = mp3_files + wav_files\n",
        "else:\n",
        "  audio_files, _ = colab_utils.upload()\n",
        "\n",
        "for fname in audio_files:\n",
        "  target_name = os.path.join(AUDIO_DIR, \n",
        "                             os.path.basename(fname).replace(' ', '_'))\n",
        "  print('Copying {} to {}'.format(fname, target_name))\n",
        "  !cp \"$fname\" $target_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_XVFoN2YOat"
      },
      "source": [
        "### Preprocesses raw audio into TFRecord dataset\n",
        "\n",
        "The audio must be formatted for training. This code breaks up training audio in 4-second clips. Furthermore, a pre-trained model with fixed weight called CREPE infers the pitch. Likewise a pretrained model computes the loudness.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsnkAHyHVrCW"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "TRAIN_TFRECORD = 'data/train.tfrecord'\n",
        "TRAIN_TFRECORD_FILEPATTERN = TRAIN_TFRECORD + '*'\n",
        "\n",
        "# Copy dataset from drive if dataset has already been created.\n",
        "drive_data_dir = os.path.join(DRIVE_DIR, 'data') \n",
        "drive_dataset_files = glob.glob(drive_data_dir + '/*')\n",
        "\n",
        "if DRIVE_DIR and len(drive_dataset_files) > 0:\n",
        "  !cp \"$drive_data_dir\"/* data/\n",
        "\n",
        "else:\n",
        "  # Make a new dataset.\n",
        "  if not glob.glob(AUDIO_FILEPATTERN):\n",
        "    raise ValueError('No audio files found. Please use the previous cell to '\n",
        "                    'upload.')\n",
        "\n",
        "  !ddsp_prepare_tfrecord \\\n",
        "    --input_audio_filepatterns=$AUDIO_FILEPATTERN \\\n",
        "    --output_tfrecord_path=$TRAIN_TFRECORD \\\n",
        "    --num_shards=10 \\\n",
        "    --alsologtostderr\n",
        "\n",
        "  # Copy dataset to drive for safe-keeping.\n",
        "  if DRIVE_DIR:\n",
        "    !mkdir \"$drive_data_dir\"/\n",
        "    print('Saving to {}'.format(drive_data_dir))\n",
        "    !cp $TRAIN_TFRECORD_FILEPATTERN \"$drive_data_dir\"/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4toX-D-AYZL"
      },
      "source": [
        "### Save dataset statistics for timbre transfer\n",
        "Calculates and pickles quantile normalizations to match loudness for the timbre transfer notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp_c8P0xApY6"
      },
      "source": [
        "from ddsp.colab import colab_utils\n",
        "import ddsp.training\n",
        "\n",
        "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
        "dataset = data_provider.get_dataset(shuffle=False)\n",
        "PICKLE_FILE_PATH = os.path.join(SAVE_DIR, 'dataset_statistics.pkl')\n",
        "\n",
        "colab_utils.save_dataset_statistics(data_provider, PICKLE_FILE_PATH, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIsq0HrzbOF7"
      },
      "source": [
        "Loading the dataset in the `ddsp` library and printing out example audio clips\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA-FOmRgYdpZ"
      },
      "source": [
        "from ddsp.colab import colab_utils\n",
        "import ddsp.training\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
        "dataset = data_provider.get_dataset(shuffle=False)\n",
        "\n",
        "try:\n",
        "  ex = next(iter(dataset))\n",
        "except StopIteration:\n",
        "  raise ValueError(\n",
        "      'TFRecord contains no examples. Please try re-running the pipeline with '\n",
        "      'different audio file(s).')\n",
        "\n",
        "colab_utils.specplot(ex['audio'])\n",
        "colab_utils.play(ex['audio'])\n",
        "\n",
        "f, ax = plt.subplots(3, 1, figsize=(14, 4))\n",
        "x = np.linspace(0, 4.0, 1000)\n",
        "ax[0].set_ylabel('loudness_db')\n",
        "ax[0].plot(x, ex['loudness_db'])\n",
        "ax[1].set_ylabel('F0_Hz')\n",
        "ax[1].set_xlabel('seconds')\n",
        "ax[1].plot(x, ex['f0_hz'])\n",
        "ax[2].set_ylabel('F0_confidence')\n",
        "ax[2].set_xlabel('seconds')\n",
        "ax[2].plot(x, ex['f0_confidence'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gvXBa7PbuyY"
      },
      "source": [
        "## Train Model\n",
        "\n",
        "Train a model conditioned only on the fundamental frequency (f0) and loudness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpwQkSIKjEMZ"
      },
      "source": [
        "Print out a tensorboard, to keep track of model training, and loss function progress."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2lx7yJneUXT"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "import tensorboard as tb\n",
        "tb.notebook.start('--logdir \"{}\"'.format(SAVE_DIR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT-8Koyvj46w"
      },
      "source": [
        "### Here we start training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poKO-mZEGYXZ"
      },
      "source": [
        "!ddsp_run \\\n",
        "  --mode=train \\\n",
        "  --alsologtostderr \\\n",
        "  --save_dir=\"$SAVE_DIR\" \\\n",
        "  --gin_file=models/solo_instrument.gin \\\n",
        "  --gin_file=datasets/tfrecord.gin \\\n",
        "  --gin_param=\"TFRecordProvider.file_pattern='$TRAIN_TFRECORD_FILEPATTERN'\" \\\n",
        "  --gin_param=\"batch_size=16\" \\\n",
        "  --gin_param=\"train_util.train.num_steps=30000\" \\\n",
        "  --gin_param=\"train_util.train.steps_per_save=300\" \\\n",
        "  --gin_param=\"trainers.Trainer.checkpoints_to_keep=10\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V95qxVjFzWR6"
      },
      "source": [
        "## Resynthesis\n",
        "\n",
        "Here we see how well the model reconstructs the training data, by printing out a training audio clip, alongside the newly reconstructed audio clip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ5PPDZVzgFR"
      },
      "source": [
        "from ddsp.colab.colab_utils import play, specplot\n",
        "import ddsp.training\n",
        "import gin\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
        "dataset = data_provider.get_batch(batch_size=1, shuffle=False)\n",
        "\n",
        "try:\n",
        "  batch = next(iter(dataset))\n",
        "except OutOfRangeError:\n",
        "  raise ValueError(\n",
        "      'TFRecord contains no examples. Please try re-running the pipeline with '\n",
        "      'different audio file(s).')\n",
        "\n",
        "# Parse the gin config.\n",
        "gin_file = os.path.join(SAVE_DIR, 'operative_config-0.gin')\n",
        "gin.parse_config_file(gin_file)\n",
        "\n",
        "# Load model\n",
        "model = ddsp.training.models.Autoencoder()\n",
        "model.restore(SAVE_DIR)\n",
        "\n",
        "# Resynthesize audio.\n",
        "outputs = model(batch, training=False)\n",
        "audio_gen = model.get_audio_from_outputs(outputs)\n",
        "audio = batch['audio']\n",
        "\n",
        "print('Original Audio')\n",
        "specplot(audio)\n",
        "play(audio)\n",
        "\n",
        "print('Resynthesis')\n",
        "specplot(audio_gen)\n",
        "play(audio_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXM2ynLQ2Wl3"
      },
      "source": [
        "## Download Checkpoint for use in Tone Transfer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WDiCyXP0tNE"
      },
      "source": [
        "from ddsp.colab import colab_utils\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "CHECKPOINT_ZIP = 'my_solo_instrument.zip'\n",
        "latest_checkpoint_fname = os.path.basename(tf.train.latest_checkpoint(SAVE_DIR))\n",
        "!cd \"$SAVE_DIR\" && zip $CHECKPOINT_ZIP $latest_checkpoint_fname* operative_config-0.gin dataset_statistics.pkl\n",
        "!cp \"$SAVE_DIR/$CHECKPOINT_ZIP\" ./\n",
        "colab_utils.download(CHECKPOINT_ZIP)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}